[{"content":"\u003cp\u003eThis course notes are in preparation and should be released around mid-May.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/intro_objective_bayes/","title":"01 - An introduction to objective bayesianism with climate science examples"},{"content":"\u003cp\u003eThis course notes are in preparation and should be released around mid-May.\u003c/p\u003e\n\u003c!-- \n## Introduction\n\n  * History of ensemble forecasting (Roots of Ensemble Forecasting, J. M. Lewis 2005)\n\n\n## Chaos theory\n\nLyapunov exponent $\\lambda$ measure the sensitivity to initial conditions\n\n$$\n| \\delta Z(t) | = e^{\\lambda t} |\\delta Z_0 |.\n$$\n\nThere could be multiple lyapunov exponent and we usually refer to the largest one, called MLE.\n\n* Periodic behavior of chaotic system must be repelling not attracting\n* Topological mixing: any given regions will eventually overlapp with any other given region\n## Types of uncertainties\n\n## Ensemble forecasting\n\nRetrospective\n\n## From weather to climate\n\n## Counterfactuals\n\n## Predictability\n\n**Palmer 2006:**\n* We should think of weather and climate prediction in terms of equations whose basic prognostic variables are probability densities $\\rho(X, t)$ where $X$ denotes some climatic variables and $t$ denotes time.\n* $\\rho(X, t)dV$ denotes the probability that at time $t$, $X$ true value lies in some volume $dV$.\n* **Fokker–Planck equation:**  partial differential equation that describes the time evolution of the probability density function of the velocity of a particle under the influence of drag forces and random forces, as in Brownian motion \n* **Liouville equation:**  describes the time evolution of the phase space distribution function (fundamental equation of statistical mechanics).\n\n* Fokker-Planck and Liouville equations describe the evolution of the climate system and are practically solved using ensemble techniques.\n* Prior estimate $\\rho_C(X)$ climatological density of $X$.\nWeather or not $X$ is predictable depends wether $\\rho(X, t)$ is sufficiently different from $\\rho_C(X)$, i.e. it is predictable if they are different\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e    \n    \u003cimg src=\"../Images/forecast_distributions_palmer_2006.png\" alt=\"Image\" style=\"width: 300px; height: auto; margin-right: 40px;\"\u003e\n    \u003cp\u003e\n    If the distributions are very different the weather forecast could be used by decision-makers. The way to compute this divergence is not clear and would depend on the specific decision making. Where one is mainly interested about extreme events then measuring the distance between the probabilities after a critical point might be prefered to an overall distance measure. This might for example be the case in figure 1.1.\n    \u003c/p\u003e\n    \n\u003c/div\u003e\n\n* $\\dot{X} = F(X)$ might be nonlinear and the Jacobian $dF/dX$ depends linearly (at least) on the state $X$\n$$\n\\frac{d \\delta X}{dt} = \\frac{dF}{dX}\\delta X.\n$$\n\nThe tangent propagator \n$$\nM(t, t_0) = \\text{exp}\\int_{t_0}^t  \\frac{dF}{dX}\\delta t'\n$$\ndepends on the nonlinear trajectory $X(t)$ about which the linearisation is performed. Hence the evolved perturbation becomes\n$$\n\\delta X(t) = M(t, t_0)\\delta X(t_0).\n$$\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e    \n    \u003cimg src=\"../Images/Lorenz69_Palmer_2006.png\" alt=\"Image\" style=\"width: 300px; height: auto; margin-right: 40px;\"\u003e\n    \u003cp\u003e\n    Assume that all points on the left of the attractor are frosty and the ones on the right side are frost-free. On the basis of the top left forecast all next weather are gonna be frosty. On the basis of the bottom forecast it is impossible to say if it is gonna be frosty or not.\n    \u003c/p\u003e\n    \n\u003c/div\u003e\n\nThe solution to Liouville equation which formally describes the evolution of $\\rho(X, t)$ arising from initial errors only can be written using the tangent operator, ie\n$$\n\\rho(X, t) = \\rho(X', t)/det(M(t, t_0))\n$$\n\nwhere $X'$ corresponds to the initial state which evolves into state $X$ at tie $t$.\n\n**Types of uncertainties:**\n* Uncertainty in observations used to define initial state\n  * \n* Uncertainty in the model used to assimilate the observations and make the forecasts\n* Uncertainty in 'external' parameters:\n  * Content of aerosols, change in CO2 emissions\n  * Should we add random volcanoes into simulations? How would this modify the distribution estimation?\n  * \n\n#### Initial uncertainty\n\nData assimilation:\n$$\nJ(X) = \\frac{1}{2}(X - X_b)^\\top B^{-1}(X - X_b) + \\frac{1}{2}(HX - Y)^\\top O^{-1}(HX - Y)\n$$\n\nwhere $X_b$ is the background state, $B$ and $O$ are covariance matrices for the pdf of background error and observation error, $H$ is the **observation operator** and $Y$ the vector of available observations. (see [Courtier et al., 1998](https://rmets.onlinelibrary.wiley.com/doi/epdf/10.1002/qj.49712455002)). The hessian \n$$\n\\nabla^2_X J = B^{-1} + H^\\top O^{-1}H\n$$\ndefines the inverse analysis error covariance matrix.\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e    \n    \u003cimg src=\"../Images/Isopleth_Palmer_2006.png\" alt=\"Image\" style=\"width: 300px; height: auto; margin-right: 40px;\"\u003e\n    \u003cp\u003e\n    We can see how an isopleth of the covariance matrix of errors evolves under the action of the tangent propagator $M$. The vector pointing along the major axis at forecast time corresponds to the leading eigenvector of the forecast error covariance matrix. Its preimage at initial time corresponds to the leading eigenvector of MtM.\n    \u003c/p\u003e\n    \n\u003c/div\u003e\n\nGiven pdfs of uncertainty based on def of $J(X)$ we can in principle perform Monte Carlo sampling of the Hessian-based initial pdf and produce ensemble forecast system based on initial sampling. There is three good reasons not to do that:\n* **Curse of dimensionality:** The sate space of a weather prediction model is too big (order $10^7$) making the process too computationally intensive. See [Lorenz 1965](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2153-3490.1965.tb01424.x) and its 28 variables model.\n* **Other uncertainties:** In practice, initial conditions uncertainties are not the only uncertainties. But the remaining uncertainties might not be well defined as part of *unknown unknowns*. Some process are well captured by simulations at the given grid size (laminar flow) but some others not at all (turbulent flow).\n* **Overconservativness:** might be prefered for very risky events. Thus one would need to sample perturbations that are likely to have significant impacts on the forecast.\n\nFor these reasons, together with the fact that the 20 to 30 first eigenvalues of $M^\\top M$ are of greater scales than the remaining ones, the initial perturbations of the ECMWF ensemble prediction system are based on the leading eigen vectors of $M^\\top M$. \n\n#### Model uncertainty\n\n* There is no underlying theory which allows us to estimate the statistical uncertainty when integratingequations of climate on a computer. \n* **Parametetrisation:** is the process of approximating the effects of unreolved processes on the resolved scales. \n* **Hierarchical uncertainties:**\n  * Multimodel ensemble (DEMETER)\n  * multiparametrisation ensemble (Meteorological Service of Canada)\n  * multiparameter ensemble (perturbation of $\\alpha$) (climateprediction.net ensemble system)\n\nThis hierarchical representation is rather pragmatic than theoretically grounded approach (and not complete).\n\n**Souldn't we use the MAP instead of the mean state???**\n\nLet's note $\\rho_m(X)$  be the representation of unresolved scales where $X$  is some resolved-scale variable. Let consider an ensemble prediction system where the grid-box mean variable is $X_0$ across all members of the ensemble. Assuming that instead of using he deterministic subgrid parameterisation $P(X_0, \\alpha)$ across all members we force the ensemble prediction system by randomly sampling $\\rho_m(X_0)$. Then the ensemble-mean would evolve differently because of nonlinearity. **Making it as a question.** Why?\n\n* We move from an arbitrary ensemble of multimodels where parametrisations difference does not represent anything meaningful to one where each ensemble member is equipped with a possible realisation of subgrid process.\n* **Reasons why it should be better (stochastic dynamic vs multimodel):**\n  * More accurate representation of model uncertainties\n  * Reduction of model systematic errors\n  * More accurate internal variability representation (important for **climate change detection**)\n\n  We can write the equations of motion of the climate/weather prediction model as\n$$\n\\dot{X} = F(X) + P + e\n$$\n\nwhere $e = \\epsilon P$ and $P$ denotes the conventional parametrisation term and $\\epsilon$ \n\n#### Types of forecast\n\n**Extended range** (monthly time scales): Used originally to find which period were predictable (more than $P_W$). In early times, the methods fro initial condition perturbations were simple:  adding random noise on initial conditions or using time lagged techniques. In 2004: singular vector ensemble initial conditions perturbations (see [Vitart 2004](https://journals.ametsoc.org/view/journals/mwre/132/12/mwr2826.1.xml)).\n\n**Medium range forecast:** Using both singular values initial perturbation and stochatsic physics.\n* [Lothar cyclone](https://en.wikipedia.org/wiki/Cyclone_Lothar) in december 1999 was exceptionally unpredictable and even 42 hours lead time there is a considerable spread in the ensemble. The best guidance deterministic forecast only predicts a weak trough in surface pressure. \n* However a couple of members show a strong vortex over France. The ensemble was able to predict something that a deterministic forecast could not. \n\n**Seasonal and decadal predictions:** Interaction between atmosphere and slower components such as oceans and land surface.\n* Predictability of ENSO are predictable seasons ahead of time using intermediate-complexity coupled ocean-atmosphere of the tropical Pacific.\n* Using inital conditions perturbation of both atospheric and ocean state.\n* Use of multimodel ensembles (DEMETER)\n\n\n**Climate change:**\n\n**Short range forecasting:** For a long time, weather forcasting was seen as a deterministic task up to 2 days. Nowadays, falshfloods and other similar events \n* Ensemble boundary conditions\n* initial perturbations\n\n**Underdispersivity and unknown unknowns**\n\n#### Uncertain forecast from deterministic dynamics\n\n* Lorenz system:\n\t* Each dote is a weather of possible climate (attractor)\n\t* Weather can be seen as a realisation of the irreducible uncertainty of the chaotic climate system\n\t* Predictability of Lorenz (like climate) is very state dependent\n\t* Phase space\n\t* If proba of initial conditions represents correctly uncertainty and model correct then we get correct estimate of forecast uncertainty\n\t* Stochastic dynamic predictions (Epstein 1969)\n\t* Liouville équation\n\n$$ \n\\frac{\\partial \\phi}{\\partial t} +  \\nabla (\\dot{X} \\phi) = 0\n$$\n\nIs familiar to continuity (ie conservation) équation for mass. Here $\\phi$ is the uncertainty distrib and $\\dot{X}$ the total derivatives wrt time of the prognostic variables defining the coordinate axes of the state space.\n\t* The total proba of any system is by def 1\n\t* The governing physical dynamics are contained on $\\dot{X}$, known as tendencies. Integration of this equation is deterministic (there are no Radom terms introduced on the right hand sides of the dynamical tendencies)\n\t* Stochastic diffusion forcings and jump processes are integrated threw Chapman-Kolmogorov equation\n\t* But direct intergation too computationally expensive\n\n\n* **personal questions:**\n  * What makes that sometimes errors of dynamical system grow exponentially and sometime not? \n  * Also how can some part of the system (eg mean state) do not have an error growing exponentially? How can we get a linear response? To some perturbations and a non linear one to others?  --\u003e","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/intro_ensemble_forecasting/","title":"03 - An introduction to ensemble forecasting"},{"content":"\u003cp\u003eThis course notes are in preparation and should be released around mid-May.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/intro_validation_probabilistic_forecasting/","title":"04 - An introduction to the validation of probabilistic forecasting"},{"content":"\u003cbase target=\"_blank\"\u003e\n\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eLynch Syndrome is associated with a significantly elevated risk of developing colorectal cancer (CRC). However, this risk can be mitigated through early detection and intervention. A pivotal diagnostic method involves identifying lesions in enterocytes using immunohistochemistry on colon tissue samples. A deficient Mismatch Repair (MMR) crypt, termed Adenomatous Crypt Foci (ACF), indicates Lynch Syndrome.\u003c/p\u003e\n\u003cp\u003eDistinguishing healthy and deficient crypts involves assessing their visual characteristics under a microscope, with healthy crypts appearing brown and ACF crypts blue. Other distinguishing criteria are explored in this project. Yet, the rarity of ACF crypts coupled with the manual microscopic examination by specialists - around 15 minutes per slide - hinders efficient diagnosis, with a single patient\u0026rsquo;s results taking around 2.5 hours due to multiple slides.\u003c/p\u003e\n\u003cp\u003eThis project\u0026rsquo;s primary objective is to harness deep learning and machine learning techniques to aid specialists in detecting enterocytes and distinguishing different crypt types. This initiative aims to expedite diagnosis, facilitating swifter patient intervention during the onset of disease symptoms. Building upon the work of Clémence Lanfranchi [reference], we seek to employ advanced computational methods to enhance the diagnostic process.\u003c/p\u003e\n\u003cp\u003eThe project unfolds in several phases:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMedical Understanding:\u003c/strong\u003e We begin by delving into the medical definition of Lynch Syndrome [reference], improving our comprehension of this condition and the intricacies of its diagnosis.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData Preprocessing:\u003c/strong\u003e We explore the data preprocessing steps, detailing the crypt segmentation methodology from Clémence Lanfranchi\u0026rsquo;s work [reference]. We also outline the ranking technique employed for distinguishing crypt types. The dataset and its preprocessing modifications are introduced, addressing the challenge of limited deficient class samples.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExperimental Protocol:\u003c/strong\u003e We present the setup of our experimental protocol, elaborating on the classification algorithms employed and their outcomes. Deep learning methods play a crucial role in our approach.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFuture Prospects:\u003c/strong\u003e The project concludes with a discussion on potential improvements, both in introducing advanced machine learning techniques and exploring alternative physiological-histological discriminating factors beyond the scope of Clémence Lanfranchi\u0026rsquo;s work [reference]. Additionally, we contemplate the project\u0026rsquo;s impact on environmental, societal, and ethical domains.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy integrating cutting-edge deep learning techniques into medical diagnosis, this project strives to fasten identification of Lynch Syndrome, ultimately leading to more timely and effective patient care.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/project_reports/Projet_MDL.pdf\"\u003e\u003cem\u003e\u003cstrong\u003eRead full report\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\n","description":"","image":"/images/projects/Lynch_projet.png","permalink":"https://hugo-profile.netlify.app/projects/lynch/","title":"Machine Learning for the detection of Deficient MMR Crypts to aid in the diagnosis of Lynch Disease"},{"content":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eDescription of the project\u0026hellip;\u003c/p\u003e\n","description":"","image":"/images/projects/ENP_projet.png","permalink":"https://hugo-profile.netlify.app/projects/nonparametric_density_estimation/","title":"Nonparametric Density and Survival Function Estimation - Multiplicative Censoring Model"},{"content":"\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2403.01865\"\u003ePaper\u003c/a\u003e recently accepted to AISTATS 2025.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eThe term \u003cem\u003ediluted causality\u003c/em\u003e is taken from \u003ca href=\"https://arxiv.org/pdf/1812.08233\"\u003eBühlmann (2018)\u003c/a\u003e and was suggested by Ed George. It aims to capture the idea that while causal mechanisms are invariant to any kind of perturbation or intervention, a weaker form of invariance—\u003cem\u003ediluted causality\u003c/em\u003e—might often be preferred by restricting the set of potential interventions, especially when the objective is predictive generalization.\u003c/p\u003e\n\u003cp\u003eThis project aims to better understand the relationship between causality, invariance, and out-of-distribution generalization. It builds on the great work of Peter Bühlmann, Nicolai Meinshausen, Jonas Peters, Dominik Rothenhäusler, Rune Christiansen, and others. I especially recommend reading the following papers, which have been foundational in clarifying the connections between causality, invariance, and robustness:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://academic.oup.com/jrsssb/article/78/5/947/7040653\"\u003ePeters et al. (2016)\u003c/a\u003e – \u003cem\u003eCausal Inference by Using Invariant Prediction: Identification and Confidence Intervals\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/pdf/1812.08233\"\u003eBühlmann (2018)\u003c/a\u003e – \u003cem\u003eInvariance, Causality and Robustness\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/8439889\"\u003eMeinshausen (2018)\u003c/a\u003e – \u003cem\u003eCausality from a Distributional Robustness Point of View\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://academic.oup.com/jrsssb/article/83/2/215/7056043\"\u003eRothenhäusler et al. (2021)\u003c/a\u003e – \u003cem\u003eAnchor Regression: Heterogeneous Data Meet Causality\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476906\"\u003eChristiansen et al. (2022)\u003c/a\u003e – \u003cem\u003eA Causal Framework for Distribution Generalization\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://academic.oup.com/ectj/article/25/2/404/6380481\"\u003eJakobsen et al. (2022)\u003c/a\u003e – \u003cem\u003eDistributional Robustness of K-Class Estimators and the PULSE\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe propose a very short introduction to the subject to help better understand this learning framework and our contribution:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"../../courses/anchor_mva_robustness\"\u003eIntroduction to Out-of-Distribution Generalization from a Causal Perspective\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","description":"","image":"/images/projects/anchor.png","permalink":"https://hugo-profile.netlify.app/projects/anchor_mva/","title":"Out-of-distribution generalisation via diluted causality"},{"content":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eDescription of the project\u0026hellip;\u003c/p\u003e\n","description":"","image":"/images/projects/ML.png","permalink":"https://hugo-profile.netlify.app/projects/mom/","title":"Robust Machine Learning - Study of the Median of Mean estimator"},{"content":"\u003cp\u003eWe here summarise the work of \u003ca href=\"https://ieeexplore.ieee.org/document/8439889\"\u003eMeinshausen (2018)\u003c/a\u003e. We recommend reading the original paper for a more complete overview of the ideas sketched here.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThe most common learning paradigm in statistical learning is arguably Empirical Risk Minimization (ERM), which can be written as:\u003c/p\u003e\n\u003cp\u003e$$\n\\arg\\min_{\\theta} \\mathbb{E}[\\ell(Y, f_{\\theta}(X))]\n$$\u003c/p\u003e\n\u003cp\u003ewhere $X \\in \\mathbb{R}^d$ is a set of covariates and $Y \\in \\mathbb{R}$ is a target variable. We aim to find the parameters $\\theta$, which parametrize the function $f_\\theta: \\mathbb{R}^d \\rightarrow \\mathbb{R}$, by minimizing the expected value of the loss $\\ell: \\mathbb{R} \\times \\mathbb{R} \\to \\mathbb{R}$.\u003c/p\u003e\n\u003cp\u003eWhile this is very useful when the goal is to predict outcomes for new samples $X$ drawn from the same distribution as the training data, it can fail dramatically when the test distribution shifts — a common scenario in real-world applications. In this context, a more robust learning framework is the minimization of the worst-case risk, where the distribution $Q$ of $(X, Y)$ is chosen from a set of possible distributions $\\mathbb{Q}$. This can be formally written as:\u003c/p\u003e\n\u003cp\u003e$$\n\\arg\\min_{\\theta} \\sup_{Q \\in \\mathbb{Q}} \\mathbb{E}[\\ell(Y, f_{\\theta}(X))]\n$$\u003c/p\u003e\n\u003cp\u003eThe class $\\mathbb{Q}$, often referred to as the \u003cem\u003euncertainty set\u003c/em\u003e, can be constrained using distributional metrics such as $f$-divergence (see \u003ca href=\"https://papers.nips.cc/paper_files/paper/2016/file/4588e674d3f0faf985047d4c3f13ed0d-Paper.pdf\"\u003eNamkoong (2016)\u003c/a\u003e) or the Wasserstein distance (see \u003ca href=\"https://link.springer.com/article/10.1007/s10107-017-1172-1\"\u003eEsfahani (2015)\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eIn this work, we consider a set of distributions $\\mathbb{Q}$ arising from interventions on covariates. We will see that allowing different sets of interventions leads to different types of robustness and generalization guarantees. The next section introduces key concepts from causality to help define intervention-based distributions.\u003c/p\u003e\n\u003ch2 id=\"the-causal-inference-paradigm\"\u003eThe Causal Inference Paradigm\u003c/h2\u003e\n\u003ch3 id=\"modularity-assumption\"\u003eModularity Assumption\u003c/h3\u003e\n\u003cp\u003eLet’s begin with a simple example. Suppose we are given two variables, temperature $T$ and altitude $A$, along with their joint distribution $p(T, A)$. Statistically, this distribution can be factored in two ways:\u003c/p\u003e\n\u003cp\u003e$$\np(A, T) = p(A \\mid T)p(T)\n$$\u003c/p\u003e\n\u003cp\u003eor\u003c/p\u003e\n\u003cp\u003e$$\np(A, T) = p(T \\mid A)p(A)\n$$\u003c/p\u003e\n\u003cp\u003eThe second factorization is considered \u003cem\u003ecausal\u003c/em\u003e because $p(T \\mid A)$ reflects a physical mechanism linking altitude to temperature, up to some noise. This mechanism is said to be \u003cem\u003emodular\u003c/em\u003e, meaning that if we intervene by changing altitude, the mechanism remains stable.\u003c/p\u003e\n\u003cp\u003eIn contrast, the first factorization is \u003cem\u003enon-causal\u003c/em\u003e, as $p(A \\mid T)$ does not represent a stable mechanism. There\u0026rsquo;s no reliable way to model how altitude would respond to changes in temperature.\u003c/p\u003e\n\u003cp\u003eIf a joint distribution is entailed by a directed acyclic graph (DAG), the graph is called \u003cem\u003ecausal\u003c/em\u003e if it respects modularity. That is, manipulating one variable does not alter the conditional distributions of the others. This becomes more intuitive under a \u003cstrong\u003eStructural Causal Model\u003c/strong\u003e (SCM), where each variable is defined by a function of its parents. Formally, an SCM $\\mathcal{C}$ consists of structural assignments:\u003c/p\u003e\n\u003cp\u003e$$\nX_i := f_i(PA_i, N_i), \\quad i = 1, \\dots, n\n$$\u003c/p\u003e\n\u003cp\u003ewhere $PA_i$ are the parents of $X_i$, $N_i$ is a noise term, and $f_i$ is a stable (modular) function. The modularity assumption implies that interventions change only the relevant functions, leaving others untouched.\u003c/p\u003e\n\u003ch3 id=\"interventions\"\u003eInterventions\u003c/h3\u003e\n\u003cp\u003eSo far, we’ve used the idea of \u003cem\u003emanipulation\u003c/em\u003e informally. In causal inference, we formalize it using the concept of \u003cem\u003eintervention\u003c/em\u003e. Given a set of variables $X$ governed by an SCM, a (strong) intervention sets a variable to a fixed value.\u003c/p\u003e\n\u003cp\u003eReturning to the altitude and temperature example, assume their relationship is captured by the SCM:\u003c/p\u003e\n\u003cp\u003e$$\nT = f(A, N)\n$$\u003c/p\u003e\n\u003cp\u003ewhere $f$ is a deterministic, modular function and $N$ is some noise. A strong intervention sets the random variable $A$ to a specific value $a$, yielding the interventional distribution:\u003c/p\u003e\n\u003cp\u003e$$\nT^{do(A=a)} = f(a, N)\n$$\u003c/p\u003e\n\u003cp\u003eNote that this distribution remains random due to the noise $N$.\u003c/p\u003e\n\u003cp\u003eMore generally, for an SCM $\\mathcal{C}$, we denote the distribution under a hard intervention as $P_X^{\\mathcal{C}, do(X_i := x_i)}$, or simply $P_X^{do(X_i := x_i)}$.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003ePhilosophical note\u003c/em\u003e: This idea aligns with Woodward’s manipulation theory of causation—understanding causation as the system’s response to manipulation.\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"distribution-generalization-via-causal-inference\"\u003eDistribution Generalization via Causal Inference\u003c/h2\u003e\n\u003cp\u003eConsider the case where $P_{X, Y}$ is entailed by the following linear SCM:\u003c/p\u003e\n\u003cp\u003e$$\nX = X\\mathbf{B} + N \\in \\mathbb{R}^d\n$$\u003c/p\u003e\n\u003cp\u003e$$\nY = X\\mathbf{b} + N_y \\in \\mathbb{R}\n$$\u003c/p\u003e\n\u003cp\u003eWe denote the interventional distribution obtained by setting some component of $X$ to a specific value as $P_{X, Y}^{do(X_i := x_i)}$.\u003c/p\u003e\n\u003cp\u003eDefine $\\mathbb{Q}$ as the set of all such interventional distributions:\u003c/p\u003e\n\u003cp\u003e$$\n\\mathbb{Q} := {P_{X, Y}^{do(X := x)} \\mid x \\in \\mathcal{X} \\subseteq \\mathbb{R}^d}\n$$\u003c/p\u003e\n\u003cp\u003eIt can be shown that for the squared loss $\\ell(Y, f_\\theta(X)) := (Y - f_\\theta(X))^2$, we have the equivalence:\u003c/p\u003e\n\u003cp\u003e$$\n\\theta^{\\text{causal}} = \\arg\\min_{\\theta} \\sup_{Q \\in \\mathbb{Q}} \\mathbb{E}[\\ell(Y, f_\\theta(X))]\n$$\u003c/p\u003e\n\u003cp\u003ewhere $f_{\\theta^{\\text{causal}}}$ is the structural equation from the SCM. The intuition is straightforward:\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{cases}\n\\infty \u0026amp; \\text{if } \\theta \\ne \\theta^{\\text{causal}} \\\n\\operatorname{Var}(N_y) \u0026amp; \\text{if } \\theta = \\theta^{\\text{causal}}\n\\end{cases}\n$$\u003c/p\u003e\n\u003cp\u003eIf $\\theta \\ne \\theta^{\\text{causal}}$, there exists some intervention that causes the loss to diverge. In contrast, if $\\theta = \\theta^{\\text{causal}}$, the loss becomes independent of $X$ and equals the variance of the noise.\u003c/p\u003e\n\u003ch2 id=\"discussion\"\u003eDiscussion\u003c/h2\u003e\n\u003cp\u003eWe proposed a framework showing that, in the linear case and for the squared loss, worst-case risk minimization for out-of-distribution generalization is equivalent to recovering the causal parameters of an SCM—when the uncertainty set $\\mathbb{Q}$ includes all possible interventions on $X$.\u003c/p\u003e\n\u003cp\u003eIn the next chapter, we explore how this approach might be overly conservative. Restricting $\\mathbb{Q}$ to a specific subset of interventions can sometimes yield better generalization. This direction builds on the work of \u003ca href=\"https://academic.oup.com/jrsssb/article/83/2/215/7056043\"\u003eRothenhäusler et al. (2021)\u003c/a\u003e and the idea of \u003cstrong\u003eanchor regression\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"../anchor_regression\"\u003eNext chapter: Anchor Regression as a Diluted Form of Causality\u003c/a\u003e\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/anchor_mva_robustness/","title":"01 - From Causal Inference to Out-of-Distribution Generalization Simulation"},{"content":"\u003cp\u003eThis course notes are in preparation and should be released around mid-May.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/intro_bayesian_uq_of_computer_experiments/","title":"02 - An introduction to uncertainty quantification of physical simulation"},{"content":"\u003cp\u003eWe here summarise the work of \u003ca href=\"https://academic.oup.com/jrsssb/article/83/2/215/7056043\"\u003eRothenhäusler et al. (2021)\u003c/a\u003e. We recommend reading the original paper for a more complete overview of the ideas sketched here.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWe are still interested in worst-case risk minimisation as described in the previous chapter. Given $X \\in \\mathbb{R}^d$ and $Y \\in \\mathbb{R}$, we aim to minimise\u003c/p\u003e\n\u003cp\u003e$$\n\\arg\\min_{\\mathbf{b}} \\sup_{Q \\in \\mathbb{Q}} \\mathbb{E}[(Y - X\\mathbf{b})^2].\n$$\u003c/p\u003e\n\u003cp\u003eWe use the squared loss and again assume a linear SCM, but now with a slightly more elaborate structure. We assume that a part of the covariates are known to be exogenous. We call these \u003cem\u003eanchor variables\u003c/em\u003e, denoted $A$. Anchor variables aim to generalise the framework of instrumental variables (IV) regression, which assumes the presence of an exogenous variable that affects $Y$ only through $X$ (exclusion restriction). The anchor framework relaxes this exclusion restriction by only assuming exogeneity of $A$.\u003c/p\u003e\n\u003cp\u003eMore concretely, the distribution of $(A, X, Y)$ is entailed by the following SCM:\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{pmatrix} X \\ Y \\ H \\end{pmatrix} = \\mathbf{B} \\begin{pmatrix} X \\ Y \\ H \\end{pmatrix} + \\varepsilon + \\mathbf{M} A,\n$$\u003c/p\u003e\n\u003cp\u003ewhere $H$ represents hidden confounders.\u003c/p\u003e\n\u003cp\u003eAssuming the graph is acyclic, the matrix $(I - \\mathbf{B})$ is invertible, and the SCM can be written as:\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{pmatrix} X \\ Y \\ H \\end{pmatrix} = (I - \\mathbf{B})^{-1}(\\varepsilon + \\mathbf{M} A).\n$$\u003c/p\u003e\n\u003cp\u003eIn this framework, we allow interventions only on the anchor variables $A$. The intervened SCM is:\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{pmatrix} X \\ Y \\ H \\end{pmatrix} = (I - \\mathbf{B})^{-1}(\\varepsilon + \\nu),\n$$\u003c/p\u003e\n\u003cp\u003ewhere $\\nu$ is the hard intervention. We denote by $P^\\nu$ the interventional distribution, and $\\mathbb{E}_\\nu$ its corresponding expectation (also referred to as the test distribution). The training distribution is denoted by $P$.\u003c/p\u003e\n\u003cp\u003eBecause of the presence of hidden confounders $H$, the causal parameters are non-identifiable. Thus, learning a causal model that remains stable under all possible interventions is impossible (see previous chapter). Interestingly, \u003ca href=\"https://academic.oup.com/jrsssb/article/83/2/215/7056043\"\u003eRothenhäusler et al. (2021)\u003c/a\u003e also show that causal parameters might even be sub-optimal for prediction in the presence of hidden confounders.\u003c/p\u003e\n\u003ch2 id=\"bounded-interventions\"\u003eBounded Interventions\u003c/h2\u003e\n\u003cp\u003eThe core idea of anchor regression is to restrict the strength of interventions on $A$. This is formalised as:\u003c/p\u003e\n\u003cp\u003e$$\n\\mathbb{Q}^{\\text{anchor}} = \\left{ P^\\nu \\mid \\nu \\nu^\\top \\preceq \\gamma , \\mathbb{E}_P[AA^\\top] \\right}.\n$$\u003c/p\u003e\n\u003cp\u003eBy constraining the set of possible interventions, we may obtain better generalisation performance. In practice, interventions are typically bounded, making this assumption reasonable.\u003c/p\u003e\n\u003ch2 id=\"robustness-under-diluted-causality\"\u003eRobustness Under Diluted Causality\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://academic.oup.com/jrsssb/article/83/2/215/7056043\"\u003eRothenhäusler et al. (2021)\u003c/a\u003e show that the worst-case risk over the set $\\mathbb{Q}^{\\text{anchor}}$ takes a particularly simple form as a causal regularisation of Empirical Risk Minimisation (ERM):\u003c/p\u003e\n\u003cp\u003e$$\n\\sup_{P^\\nu \\in \\mathbb{Q}^{\\text{anchor}}} \\mathbb{E}_\\nu[(Y - X\\mathbf{b})^2] = \\mathbb{E}_P[(Y - X\\mathbf{b})^2] + (\\gamma - 1) , \\mathbb{E}_P\\left[(P_A(Y - X\\mathbf{b}))^2\\right],\n$$\u003c/p\u003e\n\u003cp\u003ewhere $P_A(\\cdot) = \\mathbb{E}[\\cdot \\mid A]$ denotes the linear projection onto the space spanned by $A$. The parameter $\\gamma$ captures the strength of the interventions in $\\mathbb{Q}^{\\text{anchor}}$ to which we want robustness.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe first term on the right-hand side is the standard ERM loss.\u003c/li\u003e\n\u003cli\u003eThe second term is a causal regularisation term.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis second term is equivalent to the two-stage least squares formulation of instrumental variables. Special cases include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$\\gamma = 1$: standard ERM,\u003c/li\u003e\n\u003cli\u003e$\\gamma = \\infty$: IV regression,\u003c/li\u003e\n\u003cli\u003e$\\gamma = 0$: partialling-out regression, another causal inference technique.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"discussion\"\u003eDiscussion\u003c/h2\u003e\n\u003cp\u003eWe have shown how restricting the set of potential interventions may lead to better generalisation under bounded interventions. So far, this framework has considered only the quadratic loss. In the next chapter, we will see how this regularisation idea can be extended to a wider class of algorithms.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"../anchor_mva\"\u003eNext chapter: Anchor Regression Generalisation for Multivariate Algorithms\u003c/a\u003e\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/anchor_regression/","title":"02 - Anchor Regression as a Diluted Form of Causality Generalisation Simulation"},{"content":"\u003cp\u003eThis chapter will be available soon.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/anchor_mva_climate/","title":"03 - Anchor regression generalisation for multivariate algorithms"},{"content":"\u003cp\u003eWe summarise the work of \u003ca href=\"https://arxiv.org/abs/2403.01865\"\u003eDurand et al. (2025)\u003c/a\u003e. For a more comprehensive overview, we recommend reading the original paper.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWe continue working within the worst-case risk framework, but now consider a general loss function $\\mathcal{L}(X, Y; \\theta)$, whose form will be clarified later. The goal becomes solving:\u003c/p\u003e\n\u003cp\u003e$$\n\\arg\\min_{\\theta} \\sup_{Q \\in \\mathbb{Q}} \\mathbb{E}[\\mathcal{L}(X, Y; \\theta)].\n$$\u003c/p\u003e\n\u003cp\u003eAssume the observed variables $(X, Y)$ follow the linear SCM from \u003ca href=\"https://academic.oup.com/jrsssb/article/83/2/215/7056043\"\u003eRothenhäusler et al. (2021)\u003c/a\u003e:\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{pmatrix} X \\ Y \\ H \\end{pmatrix} = \\mathbf{B} \\begin{pmatrix} X \\ Y \\ H \\end{pmatrix} + \\varepsilon + \\mathbf{M} A.\n$$\u003c/p\u003e\n\u003cp\u003eGiven acyclicity of the graph, we have:\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{pmatrix} X \\ Y \\ H \\end{pmatrix} = (I - \\mathbf{B})^{-1}(\\varepsilon + \\mathbf{M} A),\n$$\u003c/p\u003e\n\u003cp\u003eor more simply, for some matrix $\\mathbf{D}$,\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{pmatrix} X \\ Y \\end{pmatrix} = \\mathbf{D}(\\varepsilon + \\mathbf{M} A).\n$$\u003c/p\u003e\n\u003ch2 id=\"bounding-intervention-covariance\"\u003eBounding Intervention Covariance\u003c/h2\u003e\n\u003cp\u003eFrom this, we can write the covariance matrix of $\\begin{pmatrix} X \\ Y \\end{pmatrix}$ as:\u003c/p\u003e\n\u003cp\u003e$$\n\\Sigma_{XY} = \\mathbf{D}\\Sigma_{\\varepsilon}\\mathbf{D}^\\top + \\mathbf{D}\\mathbf{M}\\Sigma_{A}\\mathbf{M}^\\top \\mathbf{D}^\\top,\n$$\u003c/p\u003e\n\u003cp\u003eassuming $\\varepsilon$ and $A$ are independent. Similarly, the covariance under intervention becomes:\u003c/p\u003e\n\u003cp\u003e$$\n\\Sigma_{XY}^{do(A := \\nu)} = \\mathbf{D}\\Sigma_{\\varepsilon}\\mathbf{D}^\\top + \\mathbf{D}\\mathbf{M}\\Sigma_{\\nu}\\mathbf{M}^\\top \\mathbf{D}^\\top.\n$$\u003c/p\u003e\n\u003cp\u003eWith the set of bounded interventions:\u003c/p\u003e\n\u003cp\u003e$$\n\\mathbb{Q}^{\\text{anchor}} = { P^\\nu \\mid \\nu \\nu^\\top \\preceq \\gamma , \\mathbb{E}_P[AA^\\top] },\n$$\u003c/p\u003e\n\u003cp\u003ewe obtain for all $P \\in \\mathbb{Q}^{\\text{anchor}}$:\u003c/p\u003e\n\u003cp\u003e$$\n\\Sigma_{XY}^{do(A := \\nu)} \\preceq \\mathbf{D}\\Sigma_{\\varepsilon}\\mathbf{D}^\\top + \\gamma \\mathbf{D}\\mathbf{M} \\Sigma_{A} \\mathbf{M}^\\top \\mathbf{D}^\\top.\n$$\u003c/p\u003e\n\u003cp\u003eHence, we can bound $\\Sigma_{XY}$ across this intervention family, which is valuable since many methods depend on $\\Sigma_{XY}$.\u003c/p\u003e\n\u003ch2 id=\"anchor-compatible-losses\"\u003eAnchor-Compatible Losses\u003c/h2\u003e\n\u003cp\u003eWe define a class of losses suitable for anchor regularisation.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDefinition (Anchor-compatible loss):\u003c/strong\u003e\u003cbr\u003e\n\u003cem\u003eA loss function $\\mathcal{L}(X, Y; \\theta)$ is anchor-compatible if it can be written as:\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e$$\n\\mathcal{L}(X, Y; \\theta) = f_{\\theta}(C_{XY}),\n$$\u003c/p\u003e\n\u003cp\u003e\u003cem\u003ewhere $f_\\theta : \\mathbb{R}^{d \\times p} \\to \\mathbb{R}$ is a linear map, and $C_{XY} = \\begin{pmatrix} X \\ Y \\end{pmatrix} \\otimes \\begin{pmatrix} X \\ Y \\end{pmatrix}$.\u003c/em\u003e\u003c/p\u003e\n\u003ch2 id=\"out-of-distribution-generalisation\"\u003eOut-of-Distribution Generalisation\u003c/h2\u003e\n\u003cp\u003eFor anchor-compatible losses, we have the following guarantee:\u003c/p\u003e\n\u003cp\u003eLet $(X, Y, H)$ follow the SCM above and let $\\mathcal{L}(X, Y; \\theta)$ be anchor-compatible. Then, for any $\\theta$ and $\\gamma \u0026gt; 0$:\u003c/p\u003e\n\u003cp\u003e$$\n\\sup_{P \\in \\mathbb{Q}^{\\text{anchor}}} \\mathbb{E}\u003cem\u003eP[\\mathcal{L}(X, Y; \\theta)] = f\u003c/em\u003e\\theta(\\Sigma_{XY}) + (\\gamma - 1) f_\\theta(\\Sigma_{XY|A}).\n$$\u003c/p\u003e\n\u003ch2 id=\"robustness-of-multivariate-analysis-algorithms\"\u003eRobustness of Multivariate Analysis Algorithms\u003c/h2\u003e\n\u003cp\u003eThis framework enables robustness for popular multivariate methods such as Multiple Linear Regression (MLR), Orthogonal PLS (OPLS), Reduced Rank Regression (RRR), and Partial Least Squares (PLS). However, some algorithms like Canonical Correlation Analysis (CCA) are not compatible with anchor regularisation due to the lack of theoretical guarantees.\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eMethod\u003c/th\u003e\n          \u003cth\u003eLoss\u003c/th\u003e\n          \u003cth\u003eConstraints\u003c/th\u003e\n          \u003cth\u003eCompatible\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eMLR\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$| Y - \\mathbf{W}^T X |_F^2$\u003c/td\u003e\n          \u003ctd\u003e–\u003c/td\u003e\n          \u003ctd\u003e✔\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eOPLS\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$| Y - \\mathbf{U} \\mathbf{V}^T X |_F^2$\u003c/td\u003e\n          \u003ctd\u003e$\\mathbf{U}^T \\mathbf{U} = \\mathbf{I}$\u003c/td\u003e\n          \u003ctd\u003e✔\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eRRR\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$| Y - \\mathbf{W} X |_F^2$\u003c/td\u003e\n          \u003ctd\u003e$\\text{rank}(\\mathbf{W}) = \\rho$\u003c/td\u003e\n          \u003ctd\u003e✔\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003ePLS\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$-\\text{tr}( \\mathbf{W_x}^T X^T Y \\mathbf{W_y} )$\u003c/td\u003e\n          \u003ctd\u003e$\\mathbf{W_x}^T \\mathbf{W_x} = \\mathbf{I}, \\mathbf{W_y}^T \\mathbf{W_y} = \\mathbf{I}$\u003c/td\u003e\n          \u003ctd\u003e✔\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eCCA\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$-\\text{tr}( \\mathbf{W_x}^T X^T Y \\mathbf{W_y} )$\u003c/td\u003e\n          \u003ctd\u003e$\\mathbf{W_x}^T C_X \\mathbf{W_x} = \\mathbf{I}, \\mathbf{W_y}^T C_Y \\mathbf{W_y} = \\mathbf{I}$\u003c/td\u003e\n          \u003ctd\u003e✘\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"discussion\"\u003eDiscussion\u003c/h2\u003e\n\u003cp\u003eWe showed that anchor regularisation applies to a broader class of loss functions beyond least squares. Any loss expressible as a linear map of the joint covariance $\\Sigma_{XY}$ can be anchor-regularised via a simple causal term. This extends OOD generalisation to many standard multivariate learning algorithms.\u003c/p\u003e\n\u003cp\u003eNext, we explore applications to climate change attribution.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"../anchor_mva_climate\"\u003eNext chapter: Robust estimation of forced climate response\u003c/a\u003e\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/anchor_mva/","title":"03 - Generalizing Anchor Regression to Multivariate Algorithms"},{"content":"\u003cp\u003eThis course notes are in preparation and should be released around mid-May.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/intro_detection_and_attribution/","title":"05 - An introduction to detection and attribution of climate change"},{"content":"\u003cp\u003eThis course notes are in preparation and should be released around mid-May.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/courses/intro_extreme_events_attribution/","title":"06 - An introduction to extreme events attribution"},{"content":"\u003cp\u003eThis blog post will be available soon.\u003c/p\u003e\n\u003c!-- Quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius.\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur.\n\n## Early times\n\n* History of science discovery of climate change\n  * Alexander von Humboldt\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam. Weniam, quis nostrum.\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e    \n    Alexander von Humboldt (1769 - 1859)\n    \u003cimg src=\"../Alexander_cool.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n    \u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia.\u003c/p\u003e\n    \n\u003c/div\u003e\n\nBeatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia.\n\n\n#### Fourier calculates that the Earth would be far colder if it lacked an atmosphere.\n\n  Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam. Weniam, quis nostrum, consectetur, consectetur. \n\n  \u003cdiv style=\"display: flex; align-items: center;\"\u003e\n\u003cp\u003e Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur. consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam. Weniam, quis nostrum.\u003c/p\u003e\n    \u003cimg src=\"../Fourier_cool.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n    Joseph Fourier (1768 - 1830)\n    \n\u003c/div\u003e\n\nInventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia.\n\n#### Newton shows interactions of sunlight on different gases.\n\nNeque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam. Weniam, quis nostrum, consectetur, consectetur. \n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e\nEunice Newton Foote (1819 - 1888)\n\u003cimg src=\"../Newton_cool.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n\u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur.\n\u003c/p\u003e\n    \n    \n\u003c/div\u003e\n\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi.\n\n#### Tyndall discovers that some gases block infrared radiation. He suggests that changes in the concentration of the gases could bring climate change.\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e\n  \u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\u003c/p\u003e\n    \u003cimg src=\"../Tyndall_cool.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n    John Tyndall (1820 - 1893)\n\u003c/div\u003e\n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius.\n\n#### Arrhenius publishes the first calculation of global warming from human emissions of CO2.\n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius.\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e\n  Svante August Arrhenius (1859 - 1927)\n    \u003cimg src=\"../arrhenius_cool.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n    \u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia.\u003c/p\u003e\n\n\u003c/div\u003e\n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius.\n\n#### Plass calculates that adding CO2 to the atmosphere will have a significant effect on the radiation balance.\n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius.\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e\n  \u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est..\u003c/p\u003e\n    \u003cimg src=\"../Plass_cool_reverse.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n    Gilbert Norman Plass (1920 - 2004)\n\u003c/div\u003e\n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur.\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur.\n  \n\u003cimg src=\"../Temperatures.png\" alt=\"Image\" style=\"width: 900px; height: auto; margin-right: 200px;\"\u003e\n\u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim.\n\u003c/p\u003e\n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos.\n\n#### Revelle finds that CO2 produced by humans is not readily absorbed by the oceans.\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur.\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e\n  \u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. \u003c/p\u003e\n    \u003cimg src=\"../Revelle_warm.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n    Roger Randall Dougan Revelle (1909 - 1991)\n\u003c/div\u003e\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\n#### Keeling accurately measures CO2 in the Earth’s atmosphere and detects an annual rise. The level is 315 ppm. The mean global temperature (a five-year average) is 13.9°C.\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\n\u003cdiv style=\"display: flex; align-items: center;\"\u003e\nCharles David Keeling (1928 - 2005)\n\u003cimg src=\"../Keeling_warm.png\" alt=\"Image\" style=\"width: 200px; height: auto; margin-right: 40px;\"\u003e\n\u003cp\u003eSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit.\u003c/p\u003e\n\u003c/div\u003e\n\n#### Lorenz and others point out the chaotic nature of the climate system and the possibility of sudden shifts.\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n    \n#### The International Global Atmospheric Research Program is established in 1967\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\n#### Aerosols from human activity are shown to be increasing swiftly. Bryson claims they are causing global cooling in 1970\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\n#### Manabe and his collaborators produce complex but plausible computer models that show a temperature rise of several degrees for doubled CO2 in 1975\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\n#### The World Climate Research Program is launched to coordinate international research in 1979\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\n#### Some scientists predict that a greenhouse warming “signal” should be visible by about the year 2000 in 1981\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas.\n\n#### The Montreal Protocol of the Vienna Convention requires international restrictions on the emission of ozone-destroying gases in 1987\n* 1988: The Toronto Conference calls for strict, specific limits on\ngreenhouse gas emissions; U.K. Prim\n\n#### The Intergovernmental Panel on Climate Change (IPCC) is established in 1988\n* The first IPCC report says the world has been warming and\nfuture warming seems likely in 1990\n* The second IPCC report detects a “signature” of human-caused greenhouse-effect warming; it declares that serious warming is likely in the coming century in 1995\n* The third IPCC report states baldly that global warming,\nunprecedented since the end of the last ice age, is “very likely,”\nalong with possible severe surprises. Debate effectively ends\namong all but a few scientists in 2001.\n* The fourth IPCC report warns that serious effects of warming\nhave become evident; the cost of reducing emissions would be\nfar less than the damage they will cause in 2007.\n\n#### Mt. Pinatubo erupts; Hansen predicts a cooling pattern, which will validate (by 1995) computer models of aerosol effects.\n\n#### A deadly summer heat wave in Europe accelerates the divergence between European and U.S. public opinion.\n\n#### Hurricane Katrina and other major tropical storms spur debate over the impact of global warming on storm intensity.\n    \n\n  * 1896: Svante Arrhenius and then Thomas Chamberlin due CO2 increase\n  * decreased carbon dioxide would explain the causes of the great ice\n  ages\n  * still stands today but which had to wait until\n  1987 for the Antarctic Vostok ice-core results to confirm the pivotal\n  role of atmospheric CO2 in controlling past global climate.\n  * This was because scientists at that time felt there were so many other influences on\n  global climate, from sunspots to ocean circulation, that minor\n  human influences were thought insignificant in comparison to the\n  mighty forces of astronomy and geology. This idea was reinforced\n  by research during the 1940s, which developed the theory that\n  changes in the orbit of the Earth around the sun controlled the\n  waxing and waning of the great ice ages. A second line of argument\n  was that because there is 50 times more carbon dioxide in the\n  oceans than in the atmosphere, it was conjectured that ‘The sea\n  acts as a vast equalizer’, in other words the ocean would mop up\n  our pollution.\n\n  ## Modern Science\n\n  * 1940s experiment shown that carbon dioxide did block the\n  transmission of infrared ‘long-wave’ radiation.  experiments showed there was very little\n  change in this interception if the amount of carbon dioxide was\n  doubled or halved\n  * This work was brought together\n  in 1955 by the calculations of Gilbert Plass, who concluded that\n  adding more carbon dioxide to the atmosphere would intercept\n  more infrared radiation, preventing it being lost to space and thus\n  warming the planet.\n\n\n  * argument that the oceans would soak up the extra\n  anthropogenically produced carbon dioxide.\n  * 1950s and showed that the average lifetime of a carbon\n  dioxide molecule in the atmosphere before it dissolved in the sea\n  was about ten years.\n  *  Roger Revelle: Did it stay there or diffuse back into the atmosphere? How much\n  extra CO2 could the oceans hold? Revelle’s calculations showed that\n  the complexities of the surface ocean chemistry are such that it\n  returns much of the carbon dioxide that it absorbs.the exact amount of anthropogenic carbon\n  dioxide taken up per year by the oceans is still in debate. It is\n  thought to be about 2 gigatonnes, nearly a third of the annual total\n  anthropogenic production.\n  * Charles Keeling: late 1950s and early 1960s Keeling used the most modern technology available to measure the concentration of atmospheric CO2 in Antarctica and Mauna Loa. The resulting Keeling CO2 curves have continued to climb ominously each year since the first measurement in 1958 and have become one of the major icons of global warming.\n  * Physical geosciences being favoured financially\nin the Cold War environment (Spencer Weart)\n  * Gilbert Plass published an article in 1959 in Scientific American declaring that the world’s temperature would rise by 3°C by the end of  the century.\n\n  * Why did it take so long?\n    * From 1940 till the mid-1970s the global temperature curve\nseems to have had a general downward trend (We now know that the cooling trend of the 1970s is\ndue to the decadal influence of the sunspot cycle.)\n    * discuss whether the Earth was entering the\nnext great ice age.\n    * early 1980s, when the global annual mean\ntemperature curve started to increase, that the global cooling\nscenario was questioned\n    * e late 1980s the global annual mean\ntemperature curve rose so steeply that all the dormant evidence\nfrom the late 1950s and 1960s was given prominence and the global\nwarming theory was in full swing. \n  * growing environmental awareness:\n    * Rachel Carson’s Silent Spring in 1962 \n    * Image of Earth seen from the moon in 1969\n    * Club of Rome’s 1972 report on Limits to Growth\n    * Three Mile Island nuclear reactor accident in 1979, the nuclear accident at Chernobyl in 1986\n    * Exxon Valdez oil spillage in 1989\n  *  Ozone ‘hole’:\n    * 1985 by the British Antarctic Survey of depletion of ozone over Antarctica which demonstrated the global connectivity of our environment.\n    * The 1985 Vienna Convention for the Protection of the Ozone Layer and 1987 Montreal Protocol on Substances that Deplete the Ozone layer and 1990 London and 1992 Copenhagen Adjustments and Amendments to the Protocol\n\n* So by combining (1) the science of global warming essentially\ncarried out by the mid-1960s, (2) the frightening upturn in the\nglobal temperature data set at the end of the 1980s, (3) our\nincreased knowledge of how past climate has reacted to changes\nin atmospheric carbon dioxide in the 1980s, (4) the emergence\nof the global environmental awareness in the late 1980s, and\n(5) the media’s savage interest in the confrontational nature of the\ndebate, we are led to the final recognition of the global warming\nhypothesis.\n\n#### Further readings\n[Detection and Attribution of climate Change: A step back](../DandA_02/) --\u003e","description":"","image":"/images/global_warming.png","permalink":"https://hugo-profile.netlify.app/blogs/history_climate_change/","title":"A Short History of Climate Change Science"},{"content":"\u003cp\u003eThis blog post will be available soon.\u003c/p\u003e\n\u003c!-- \n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius.\n\n## Introduction\n\n* Short intro to history to climate change science\n\nQuasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur.\n\n## Detection and attibution of trends (1980 - 2003)\n\n### Methodologies\n* Fingerprint\n* Optimal Fingerprint\n    * OF as linear regression\n    * Bayesian OF\n    * EIV OF\n    * GEV OF\n\n## Extreme event attribution (2003 - 2018)\n\n### Methodologies\n* Probabilistic\n* Storyline\n* Statistical\n* Dynamical Adjustment\n\n### A causal perspective\n\n## Operationalisation of extreme events attribution (2018 - nowaday)\n\n### Challenges\n\n### Teams\n* WWA\n* IPSL --\u003e","description":"","image":"/images/D_an_A.png","permalink":"https://hugo-profile.netlify.app/blogs/danda_step_back/","title":"Detection adn Attribution of Climate Change: A step back"},{"content":"\u003cbase target=\"_blank\"\u003e\n\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eDuring my recent end-of-study internship at the LOCEAN-IPSL laboratory, I delved into the intriguing realm of coupled ocean-atmosphere models calibration. This report unveils the outcomes of this exploration, along with the novel research directions that emerged.\u003c/p\u003e\n\u003cp\u003eThe central inquiry of this project revolves around the applicability of the History Matching technique, also known as Iterative Refocussing, in fine-tuning coupled ocean-atmosphere models. Using a simplified model, the Lorenz-96, which can be seen as an approximation of an Atmosphere Ocean General Circulation Model, I demonstrated the potency of the History Matching method in effectively constraining the model\u0026rsquo;s parameter search space. Notably, this breakthrough was validated across scenarios resembling AMIP (Atmospheric Model Intercomparison Project) and OMIP (Ocean Model Intercomparison Project) experiments. In AMIP-style setups, a pared-down atmosphere model reacts to ocean observations, while in OMIP-style experiments, a simplified ocean model responds to atmospheric observations.\u003c/p\u003e\n\u003cp\u003eThe report also introduces valuable insights derived from the History Matching method. It proposes a strategy to streamline the process by employing linear (Empirical Orthogonal Functions) or non-linear (Autoencoders) dimensionality reduction techniques, leading to a significant reduction in the number of metrics employed. Furthermore, the project sheds light on the potential replacement of Gaussian Process Regressors in History Matching with promising alternatives: Random Forest and Bayesian Neural Networks. Though these propositions demand further validation, they hold exciting prospects for enhancing model emulation.\u003c/p\u003e\n\u003cp\u003eAmidst these advancements, the report underscores the paramount importance of accessible tools for accurately and straightforwardly gauging prediction uncertainties across various models. The research journey embarked upon during this internship not only contributes to refining coupled ocean-atmosphere models but also opens doors to novel techniques and insights that can reverberate across diverse scientific domains.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/project_reports/Rapport_Stage.pdf\"\u003e\u003cem\u003e\u003cstrong\u003eRead full report\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\n","description":"","image":"/images/projects/HM.png","permalink":"https://hugo-profile.netlify.app/projects/history_matching/","title":"History Matching for climate model tuning - experiments on the Lorenz96 toy model"}]