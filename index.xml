<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homer Durand</title>
    <link>https://hugo-profile.netlify.app/</link>
    <description>Recent content on Homer Durand</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Apr 2025 23:29:21 +0530</lastBuildDate>
    <atom:link href="https://hugo-profile.netlify.app/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Out-of-distribution Generalisation via Diluted Causality</title>
      <link>https://hugo-profile.netlify.app/projects/anchor_mva/</link>
      <pubDate>Tue, 01 Apr 2025 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/projects/anchor_mva/</guid>
      <description>&lt;p&gt;ðŸ“„ &lt;a href=&#34;https://arxiv.org/abs/2403.01865&#34;&gt;Paper accepted at AISTATS 2025&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;&#xA;&lt;p&gt;The term &lt;em&gt;diluted causality&lt;/em&gt; comes from &lt;a href=&#34;https://arxiv.org/pdf/1812.08233&#34;&gt;BÃ¼hlmann (2018)&lt;/a&gt;, inspired by a suggestion from &lt;a href=&#34;https://statistics.wharton.upenn.edu/profile/edgeorge/&#34;&gt;Edward George&lt;/a&gt;. It reflects the notion that while causal mechanisms are expected to be invariant under all possible interventions, a weaker form of invarianceâ€”&lt;em&gt;diluted causality&lt;/em&gt;â€”can be more desirable in practice. This weaker notion restricts the set of interventions to those most relevant for predictive generalisation.&lt;/p&gt;&#xA;&lt;p&gt;This project investigates the interplay between &lt;strong&gt;causality&lt;/strong&gt;, &lt;strong&gt;invariance&lt;/strong&gt;, and &lt;strong&gt;out-of-distribution (OOD) generalisation&lt;/strong&gt;. It builds upon influential work by Peter BÃ¼hlmann, Nicolai Meinshausen, Jonas Peters, Dominik RothenhÃ¤usler, Rune Christiansen, and others.&lt;/p&gt;</description>
    </item>
    <item>
      <title>History Matching for climate model tuning - experiments on the Lorenz96 toy model</title>
      <link>https://hugo-profile.netlify.app/projects/history_matching/</link>
      <pubDate>Tue, 03 Sep 2024 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/projects/history_matching/</guid>
      <description>&lt;base target=&#34;_blank&#34;&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;&#xA;&lt;p&gt;During my end-of-study internship at the LOCEAN-IPSL laboratory, I have been working on coupled ocean-atmosphere models calibration.&lt;/p&gt;&#xA;&lt;p&gt;The ccentral goal of the the project was to better understand if History Matching technique was adapated for calibrating coupled ocean-atmosphere models. Using a simplified model, the two layers Lorenz-96 we demonstrated that History Matching method effectively constrained the model&amp;rsquo;s parameter search space. Notably, this was validated across scenarios resembling AMIP (Atmospheric Model Intercomparison Project) and OMIP (Ocean Model Intercomparison Project) experiments.&lt;/p&gt;</description>
    </item>
    <item>
      <title>01 - An introduction to objective bayesianism with climate science examples</title>
      <link>https://hugo-profile.netlify.app/courses/intro_objective_bayes/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/intro_objective_bayes/</guid>
      <description>&lt;p&gt;This course notes are in preparation and should be released around mid-May.&lt;/p&gt;</description>
    </item>
    <item>
      <title>03 - An introduction to ensemble forecasting</title>
      <link>https://hugo-profile.netlify.app/courses/intro_ensemble_forecasting/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/intro_ensemble_forecasting/</guid>
      <description>&lt;p&gt;This course notes are in preparation and should be released around mid-May.&lt;/p&gt;&#xA;&lt;!-- &#xA;## Introduction&#xA;&#xA;  * History of ensemble forecasting (Roots of Ensemble Forecasting, J. M. Lewis 2005)&#xA;&#xA;&#xA;## Chaos theory&#xA;&#xA;Lyapunov exponent $\lambda$ measure the sensitivity to initial conditions&#xA;&#xA;$$&#xA;| \delta Z(t) | = e^{\lambda t} |\delta Z_0 |.&#xA;$$&#xA;&#xA;There could be multiple lyapunov exponent and we usually refer to the largest one, called MLE.&#xA;&#xA;* Periodic behavior of chaotic system must be repelling not attracting&#xA;* Topological mixing: any given regions will eventually overlapp with any other given region&#xA;## Types of uncertainties&#xA;&#xA;## Ensemble forecasting&#xA;&#xA;Retrospective&#xA;&#xA;## From weather to climate&#xA;&#xA;## Counterfactuals&#xA;&#xA;## Predictability&#xA;&#xA;**Palmer 2006:**&#xA;* We should think of weather and climate prediction in terms of equations whose basic prognostic variables are probability densities $\rho(X, t)$ where $X$ denotes some climatic variables and $t$ denotes time.&#xA;* $\rho(X, t)dV$ denotes the probability that at time $t$, $X$ true value lies in some volume $dV$.&#xA;* **Fokkerâ€“Planck equation:**  partial differential equation that describes the time evolution of the probability density function of the velocity of a particle under the influence of drag forces and random forces, as in Brownian motion &#xA;* **Liouville equation:**  describes the time evolution of the phase space distribution function (fundamental equation of statistical mechanics).&#xA;&#xA;* Fokker-Planck and Liouville equations describe the evolution of the climate system and are practically solved using ensemble techniques.&#xA;* Prior estimate $\rho_C(X)$ climatological density of $X$.&#xA;Weather or not $X$ is predictable depends wether $\rho(X, t)$ is sufficiently different from $\rho_C(X)$, i.e. it is predictable if they are different&#xA;&#xA;&lt;div style=&#34;display: flex; align-items: center;&#34;&gt;    &#xA;    &lt;img src=&#34;../Images/forecast_distributions_palmer_2006.png&#34; alt=&#34;Image&#34; style=&#34;width: 300px; height: auto; margin-right: 40px;&#34;&gt;&#xA;    &lt;p&gt;&#xA;    If the distributions are very different the weather forecast could be used by decision-makers. The way to compute this divergence is not clear and would depend on the specific decision making. Where one is mainly interested about extreme events then measuring the distance between the probabilities after a critical point might be prefered to an overall distance measure. This might for example be the case in figure 1.1.&#xA;    &lt;/p&gt;</description>
    </item>
    <item>
      <title>04 - An introduction to the validation of probabilistic forecasting</title>
      <link>https://hugo-profile.netlify.app/courses/intro_validation_probabilistic_forecasting/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/intro_validation_probabilistic_forecasting/</guid>
      <description>&lt;p&gt;This course notes are in preparation and should be released around mid-May.&lt;/p&gt;</description>
    </item>
    <item>
      <title>01 - From causal inference to out-of-distribution generalization simulation</title>
      <link>https://hugo-profile.netlify.app/courses/anchor_mva_robustness/</link>
      <pubDate>Mon, 03 Apr 2023 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/anchor_mva_robustness/</guid>
      <description>&lt;p&gt;We here summarise the work of &lt;a href=&#34;https://ieeexplore.ieee.org/document/8439889&#34;&gt;Meinshausen (2018)&lt;/a&gt;. We recommend reading the original paper for a more complete overview of the ideas sketched here.&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The most common learning paradigm in statistical learning is arguably Empirical Risk Minimization (ERM), which can be written as:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\arg\min_{\theta} \mathbb{E}[\ell(Y, f_{\theta}(X))]&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;where $X \in \mathbb{R}^d$ is a set of covariates and $Y \in \mathbb{R}$ is a target variable. We aim to find the parameters $\theta$, which parametrize the function $f_\theta: \mathbb{R}^d \rightarrow \mathbb{R}$, by minimizing the expected value of the loss $\ell: \mathbb{R} \times \mathbb{R} \to \mathbb{R}$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>02 - An introduction to uncertainty quantification of physical simulation</title>
      <link>https://hugo-profile.netlify.app/courses/intro_bayesian_uq_of_computer_experiments/</link>
      <pubDate>Mon, 03 Apr 2023 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/intro_bayesian_uq_of_computer_experiments/</guid>
      <description>&lt;p&gt;This course notes are in preparation and should be released around mid-May.&lt;/p&gt;</description>
    </item>
    <item>
      <title>02 - Anchor Regression as a diluted form of causality</title>
      <link>https://hugo-profile.netlify.app/courses/anchor_regression/</link>
      <pubDate>Mon, 03 Apr 2023 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/anchor_regression/</guid>
      <description>&lt;p&gt;We here summarise the work of &lt;a href=&#34;https://academic.oup.com/jrsssb/article/83/2/215/7056043&#34;&gt;RothenhÃ¤usler et al. (2021)&lt;/a&gt;. We recommend reading the original paper for a more complete overview of the ideas sketched here.&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;We are still interested in worst-case risk minimisation as described in the previous chapter. Given $X \in \mathbb{R}^d$ and $Y \in \mathbb{R}$, we aim to minimise&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\arg\min_{\mathbf{b}} \sup_{Q \in \mathbb{Q}} \mathbb{E}[(Y - X\mathbf{b})^2].&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;We use the squared loss and again assume a linear SCM, but now with a slightly more elaborate structure. We assume that a part of the covariates are known to be exogenous. We call these &lt;em&gt;anchor variables&lt;/em&gt;, denoted $A$. Anchor variables aim to generalise the framework of instrumental variables (IV) regression, which assumes the presence of an exogenous variable that affects $Y$ only through $X$ (exclusion restriction). The anchor framework relaxes this exclusion restriction by only assuming exogeneity of $A$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>03 - Anchor regression generalisation for multivariate algorithms</title>
      <link>https://hugo-profile.netlify.app/courses/anchor_mva_climate/</link>
      <pubDate>Mon, 03 Apr 2023 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/anchor_mva_climate/</guid>
      <description>&lt;p&gt;This chapter will be available soon.&lt;/p&gt;</description>
    </item>
    <item>
      <title>03 - Generalizing Anchor Regression to Multivariate Algorithms</title>
      <link>https://hugo-profile.netlify.app/courses/anchor_mva/</link>
      <pubDate>Mon, 03 Apr 2023 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/anchor_mva/</guid>
      <description>&lt;p&gt;We here summarise the work of &lt;a href=&#34;https://arxiv.org/abs/2403.01865&#34;&gt;Durand et al. (2025)&lt;/a&gt;. We recommend reading the original paper for a more complete overview of the ideas sketched here.&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;We continue working within the worst-case risk framework, but now consider a general loss function $\mathcal{L}(X, Y; \theta)$, whose form will be clarified later. The goal becomes solving:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\arg\min_{\theta} \sup_{Q \in \mathbb{Q}} \mathbb{E}[\mathcal{L}(X, Y; \theta)].&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;Assume the observed variables $(X, Y)$ follow the linear SCM from &lt;a href=&#34;https://academic.oup.com/jrsssb/article/83/2/215/7056043&#34;&gt;RothenhÃ¤usler et al. (2021)&lt;/a&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>05 - An introduction to detection and attribution of climate change</title>
      <link>https://hugo-profile.netlify.app/courses/intro_detection_and_attribution/</link>
      <pubDate>Mon, 03 Apr 2023 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/intro_detection_and_attribution/</guid>
      <description>&lt;p&gt;This course notes are in preparation and should be released around mid-May.&lt;/p&gt;</description>
    </item>
    <item>
      <title>06 - An introduction to extreme events attribution</title>
      <link>https://hugo-profile.netlify.app/courses/intro_extreme_events_attribution/</link>
      <pubDate>Mon, 03 Apr 2023 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/courses/intro_extreme_events_attribution/</guid>
      <description>&lt;p&gt;This course notes are in preparation and should be released around mid-May.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning for the detection of Deficient MMR Crypts to aid in the diagnosis of Lynch Disease</title>
      <link>https://hugo-profile.netlify.app/projects/lynch/</link>
      <pubDate>Sat, 03 Apr 2021 23:29:21 +0530</pubDate>
      <guid>https://hugo-profile.netlify.app/projects/lynch/</guid>
      <description>&lt;base target=&#34;_blank&#34;&gt;&#xA;&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;&#xA;&lt;p&gt;Lynch Syndrome is associated with a significantly elevated risk of developing colorectal cancer (CRC). However, this risk can be mitigated through early detection and intervention. A pivotal diagnostic method involves identifying lesions in enterocytes using immunohistochemistry on colon tissue samples. A deficient Mismatch Repair (MMR) crypt, termed Adenomatous Crypt Foci (ACF), indicates Lynch Syndrome.&lt;/p&gt;&#xA;&lt;p&gt;Distinguishing healthy and deficient crypts involves assessing their visual characteristics under a microscope, with healthy crypts appearing brown and ACF crypts blue. Other distinguishing criteria are explored in this project. Yet, the rarity of ACF crypts coupled with the manual microscopic examination by specialists - around 15 minutes per slide - hinders efficient diagnosis, with a single patient&amp;rsquo;s results taking around 2.5 hours due to multiple slides.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
